{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95655667",
   "metadata": {},
   "source": [
    "# Implementation of Self Instruct : \n",
    "\n",
    "Paper Link : https://arxiv.org/abs/2212.10560\n",
    "\n",
    "### What is our Goal ? : Create 1000 rows of data for finetuning from 10 rows of data?\n",
    "\n",
    "- So How does a row of data ready for finetuning look like?\n",
    "- It consists of 2 things. It has a prompt and a completion.\n",
    "```\n",
    "{\"prompt\": \"Classify the sentiment of the following movie review:\\n\\nInput: This movie was absolutely terrible. The acting was wooden, the plot made no sense, and I was bored throughout.\\n\\nOutput:\", \"completion\": \" Negative\"}\n",
    "{\"prompt\": \"Determine whether the following statement is a fact or opinion:\\n\\nInput: The Earth orbits around the Sun.\\n\\nOutput:\", \"completion\": \" Fact\"}\n",
    "```\n",
    "- This was an example of classification.\n",
    "\n",
    "\n",
    "- Here's another.\n",
    "```\n",
    "{\"prompt\": \"Summarize the following text in one sentence:\\n\\nInput: The Industrial Revolution, which took place from the 18th to 19th centuries, was a period during which predominantly agrarian, rural societies in Europe and America became industrial and urban. This period saw the mechanization of manufacturing, improved transportation systems, and significant technological innovations. It transformed the daily lives of people and had far-reaching effects on socioeconomic and cultural conditions.\\n\\nOutput:\", \"completion\": \" The Industrial Revolution was a period of rapid industrialization and urbanization in Europe and America, characterized by technological advancements that dramatically changed society and the economy.\"}\n",
    "```\n",
    "\n",
    "\n",
    "### Steps to do that :\n",
    "\n",
    "- Begin with a Seed Set of Human-Written Instructions: Start by compiling a collection of well-crafted instructions that serve as the foundation for generating new tasks. Examples of instructions include:\n",
    "\n",
    "    - {\"instruction\": \"Design a 3-ingredient snack that meets the specified criteria, and provide a short explanation for each ingredient's role in the snack.\"}\n",
    "    - {\"instruction\": \"Find a healthier alternative for each of the given options.\"}\n",
    "- Generate New Instructions: Utilize a language model to generate a new set of instructions based on the seed tasks. This process involves creating prompts that guide the model to generate instructions similar to the seed tasks. The generated instructions are then filtered to ensure they are not excessively similar to existing instructions using the ROUGE-L similarity score.\n",
    "\n",
    "- Classify Instructions: Determine whether each instruction corresponds to a classification or non-classification task. This classification is essential for selecting the appropriate template when generating instances for each instruction.\n",
    "\n",
    "- Generate Instances: For each instruction, use a suitable template (either input-first or output-first) to generate instances. The template is tailored to the task type (classification or non-classification). The generated instances are then extracted from the model's response and added to the metadata of each instruction.\n",
    "    - Here's how a complete instance looks : \n",
    "    - {\"instruction\": \"Design a 3-ingredient snack that meets the specified criteria, and provide a short explanation for each ingredient's role in the snack, \"examples\": [{\"class_label\": \"Sweet & Savory\", \"input\": {\"ingredient1\": \"Apple slices\", \"explain1\": \"Providing natural sweetness and crisp texture\", \"ingredient2\": \"Cheddar cheese\", \"explain2\": \"Adding a rich, savory flavor and creamy texture\", \"ingredient3\": \"Walnuts\", \"explain3\": \"Adding crunch and earthy flavor\"}, \"output\": \"Sweet & Savory\"}, {\"class_label\": \"Sweet Treat\", \"input\": {\"ingredient1\": \"Pineapple chunks\", \"explain1\": \"Adding natural sweetness and juicy texture\", \"ingredient2\": \"Dark chocolate chips\", \"explain2\": \"Providing rich, sweet flavor and indulgent texture\", \"ingredient3\": \"Coconut flakes\", \"explain3\": \"Adding tropical flavor and extra crunch\"}, \"output\": \"Sweet Treat\"}, {\"class_label\": \"Savory Snack\", \"input\": {\"ingredient1\": \"Baby carrots\", \"explain1\": \"Providing crunchy texture and mild sweetness\", \"ingredient2\": \"Cream cheese\", \"explain2\": \"Adding rich, creamy flavor and smooth texture\", \"ingredient3\": \"Chopped pecans\", \"explain3\": \"Adding nutty flavor and extra crunch\"}, \"output\": \"Savory Snack\"}]}\n",
    "\n",
    "- Prepare data for finetuning : Now, we take each instance, clean and filter out duplicate instances and shuffles the remaining instances and finally, the script saves the encoded instances to a JSONL file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3859e1",
   "metadata": {},
   "source": [
    "# Setting up the environment and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfeb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from groq import Groq  # Import the Groq client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from templates.clf_task_template import template_1\n",
    "from templates.instance_gen_template import output_first_template_for_clf, input_first_template_for_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1b714",
   "metadata": {},
   "source": [
    "# Setting up a function to make use of the free Llama-3 API available from Groq\n",
    "\n",
    "### Function Arguments :\n",
    "- Prompt: List of prompts to be passed to API\n",
    "- Stop Sequences: For every prompt, only return the response up until the stop sequence is encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9a5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Groq API\n",
    "groq_api_key = \"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\"\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "# Function to make requests to Groq API\n",
    "def make_requests(prompts, stop_sequences=[], retries=3):\n",
    "    response = None\n",
    "    retry_cnt = 0\n",
    "    backoff_time = 30\n",
    "    results = []\n",
    "\n",
    "    while retry_cnt <= retries:\n",
    "        try:\n",
    "            for prompt in prompts:\n",
    "                chat_completion = client.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    model=\"llama3-8b-8192\"\n",
    "                )\n",
    "                response = chat_completion.choices[0].message.content.strip()\n",
    "                for stop_seq in stop_sequences:\n",
    "                    if stop_seq in response:\n",
    "                        print(\"\\n\\nOriginal response\")\n",
    "                        print(response)\n",
    "                        print(\"\\n\\nFound stop sequence \", stop_seq)\n",
    "                        print(response.split(stop_seq))\n",
    "                        response = response.split(stop_seq)[0]\n",
    "                        break\n",
    "                results.append({\n",
    "                    \"prompt\": prompt,\n",
    "                    \"response\": {\"choices\": [{\"text\": response}]},\n",
    "                    \"created_at\": str(datetime.now()),\n",
    "                })\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Retrying in {backoff_time} seconds...\")\n",
    "            time.sleep(backoff_time)\n",
    "            backoff_time *= 1.5\n",
    "            retry_cnt += 1\n",
    "            \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aad315",
   "metadata": {},
   "source": [
    "### Here's an example on how to use the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2e6d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original response\n",
      "Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\n",
      "\n",
      "\n",
      "Found stop sequence  you\n",
      "[\"Hello! It's nice to meet \", '. Is there something I can help ', ' with, or would ', ' like to chat?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'Hello',\n",
       "  'response': {'choices': [{'text': \"Hello! It's nice to meet \"}]},\n",
       "  'created_at': '2024-07-12 10:39:50.680304'},\n",
       " {'prompt': 'What are 3 breeds of cats ?',\n",
       "  'response': {'choices': [{'text': 'Here are three breeds of cats:\\n\\n1. Siamese: A short-haired breed from Thailand, known for its pointy ears and striking blue eyes.\\n2. Persian: A long-haired breed with a flat face and a thick, fluffy coat. They come in a variety of colors and are known for their calm and affectionate nature.\\n3. Maine Coon: A large and muscular breed from North America, known for its distinctive shaggy coat and friendly, outgoing personality. They are often referred to as \"gentle giants\" due to their size and gentle nature.'}]},\n",
       "  'created_at': '2024-07-12 10:39:51.618594'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_requests(\n",
    "    prompts=[\"Hello\", \"What are 3 breeds of cats ?\"], \n",
    "    stop_sequences=[\"you\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87e77b",
   "metadata": {},
   "source": [
    "# Load Seed Tasks \n",
    "\n",
    "Set of Human Written Instructions which we shall be using to expand i.e. from 50 -> 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d72c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load seed tasks from a JSONL file\n",
    "seed_tasks_path = \"data/seed_tasks.jsonl\"\n",
    "seed_tasks = [json.loads(line) for line in open(seed_tasks_path, \"r\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f6c4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Is there anything I can eat for a breakfast that doesn't include eggs, yet includes protein, and has roughly 700-1000 calories?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_instructions = [task[\"instruction\"] for task in seed_tasks]\n",
    "\n",
    "# Example of an instruction\n",
    "seed_instructions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3409855",
   "metadata": {},
   "source": [
    "# Generate Similar Instructions\n",
    "\n",
    "#### Here's in plain English what this function does : \n",
    "- The generate_instructions function takes a list of seed tasks and generates a specified number of new instructions. It uses a language model to generate the new instructions based on the seed tasks, and then filters out instructions that are too similar to existing instructions using the ROUGE-L similarity score. The function returns a list of new instructions and a list of metadata for each instruction, which includes the most similar existing instructions and their similarity scores, as well as the average similarity score and a request index.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9842c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instructions(seed_tasks, num_instructions=10):\n",
    "    instructions = []\n",
    "    metadata = []\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    seed_instructions = [task[\"instruction\"] for task in seed_tasks]\n",
    "    machine_instructions = []\n",
    "    request_idx = 0\n",
    "\n",
    "    for i in range(num_instructions):\n",
    "        # Construct the prompt\n",
    "        seed_instructions_sample = [task[\"instruction\"] for task in random.sample(seed_tasks, 3)]\n",
    "        \n",
    "        prompt = \"Generate a new instruction for a task that is similar to following instructions. Format your response as a JSON object with the key 'instruction'.Strictly Output JSON and nothing else.\\n\\n\"\n",
    "        prompt += \"Examples:\\n\"\n",
    "        prompt += '{\"instruction\": \"What is the relation between the given pairs?\"}\\n'\n",
    "        prompt += '{\"instruction\": \"Generate a one-sentence description for each of the following people.\"}\\n'\n",
    "        prompt += \"\\n\".join(seed_instructions_sample)\n",
    "        prompt += \"\\n\\nNew instruction:\"\n",
    "\n",
    "        # Call the make_requests function to generate a new instruction\n",
    "        response = make_requests([prompt], stop_sequences=[])[0][\"response\"][\"choices\"][0][\"text\"]\n",
    "\n",
    "        # Parse the JSON response and extract the new instruction\n",
    "        try:\n",
    "            new_instruction = json.loads(response)[\"instruction\"]\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON response: {response}\")\n",
    "            continue\n",
    "\n",
    "        # Compute ROUGE-L similarity with seed and machine-generated instructions\n",
    "        all_instructions = seed_instructions + machine_instructions\n",
    "        with Pool(4) as p:\n",
    "            rouge_scores = p.map(partial(scorer.score, new_instruction), all_instructions)\n",
    "        rouge_scores = [score[\"rougeL\"].fmeasure for score in rouge_scores]\n",
    "\n",
    "        # If the new instruction is too similar to existing instructions, skip it\n",
    "        if max(rouge_scores) > 0.7:\n",
    "            continue\n",
    "\n",
    "        # Add the generated instruction and metadata to the lists\n",
    "        instructions.append(new_instruction)\n",
    "        metadata.append({\n",
    "            \"most_similar\": {\n",
    "                all_instructions[i]: rouge_scores[i] for i in np.argsort(rouge_scores)[-10:][::-1]\n",
    "            },\n",
    "            \"avg_similarity_score\": float(np.mean(rouge_scores)),\n",
    "            \"request_idx\": request_idx\n",
    "        })\n",
    "        machine_instructions.append(new_instruction)\n",
    "        request_idx += 1\n",
    "\n",
    "    return instructions, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aadb1667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON response: {\n",
      "\"instruction\": \"Write a concise summary that highlights the main points of the given text, focusing on the key arguments and supporting evidence.\"\n"
     ]
    }
   ],
   "source": [
    "new_instructions, new_metadata = generate_instructions(seed_tasks, num_instructions=10)\n",
    "\n",
    "# Save the generated instructions and metadata to a JSONL file\n",
    "with open(\"generated_instructions.jsonl\", \"w\") as f:\n",
    "    for instruction, metadata in zip(new_instructions, new_metadata):\n",
    "        f.write(json.dumps({\n",
    "            \"instruction\": instruction,\n",
    "            \"metadata\": metadata\n",
    "        }) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0778b8",
   "metadata": {},
   "source": [
    "# Checking if Classification or not for generating Instances\n",
    "\n",
    "In plain English, this function takes a list of instructions and uses a language model to determine whether each instruction is a classification task or not. It does this by constructing a prompt that asks whether the instruction is a classification task, sending the prompt to the language model, parsing the response, and extracting the classification label. The function then returns a list of dictionaries, where each dictionary contains an instruction and a boolean value indicating whether that instruction is a classification task or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7208d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_instructions(instructions):\n",
    "    prefix = template_1\n",
    "    classified_instructions = []\n",
    "\n",
    "    for instruction in instructions:\n",
    "        # Construct the prompt\n",
    "        prompt = prefix + \" \" + instruction + \"\\n\" + \"Is it classification?. Format your response as a JSON object with the key 'is_classification' and value 'yes' or 'no' only for the last instruction.Strictly Output JSON and nothing else.\\n\\n\"\n",
    "        \n",
    "        response = make_requests([prompt], stop_sequences=[])[0][\"response\"][\"choices\"][0][\"text\"]\n",
    "        print(\"Response\", response)\n",
    "\n",
    "        # Parse the response and extract the classification label\n",
    "        is_classification = \"yes\" if \"yes\" in response else \"no\"\n",
    "        \n",
    "        if is_classification.lower() == \"yes\":\n",
    "            is_classification = True\n",
    "        else:\n",
    "            is_classification = False\n",
    "\n",
    "        # Add the classification label to the instruction data\n",
    "        instruction_data = {\n",
    "            \"instruction\": instruction,\n",
    "            \"is_classification\": is_classification\n",
    "        }\n",
    "        classified_instructions.append(instruction_data)\n",
    "\n",
    "    return classified_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9121b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response JSON output:\n",
      "\n",
      "{\n",
      "\"is_classification\": \"no\"\n",
      "}\n",
      "Response Here is the response in JSON format:\n",
      "\n",
      "{\n",
      "\"is_classification\": \"yes\"\n",
      "}\n",
      "Response ```\n",
      "{\n",
      "\"is_classification\": \"yes\"\n",
      "}\n",
      "```\n",
      "Response {\n",
      "\"is_classification\": \"yes\"\n",
      "Response Here is the JSON response:\n",
      "\n",
      "{\n",
      "\"is_classification\": \"no\"\n",
      "}\n",
      "Response {\n",
      "\"is_classification\": \"yes\"\n",
      "}\n",
      "Response {\n",
      "\"is_classification\": \"yes\"\n",
      "}\n",
      "Response Here is the JSON object:\n",
      "\n",
      "{\n",
      "\"is_classification\": \"yes\"\n",
      "}\n",
      "Response {\n",
      "\"is_classification\": \"yes\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Open the existing JSONL file with metadata\n",
    "with open(\"generated_instructions.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Extract the instructions from the data\n",
    "instructions = [item[\"instruction\"] for item in data]\n",
    "\n",
    "# Use the `classify_instructions` function to determine the value of `is_classification` for each instruction\n",
    "classified_instructions = classify_instructions(instructions)\n",
    "\n",
    "# Add the `is_classification` field to each instruction in the data\n",
    "for item, classification in zip(data, classified_instructions):\n",
    "    item[\"metadata\"][\"is_classification\"] = classification[\"is_classification\"]\n",
    "\n",
    "# Save the updated data to a new JSONL file\n",
    "with open(\"classified_instructions.jsonl\", \"w\") as f:\n",
    "    for item in data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998171a2",
   "metadata": {},
   "source": [
    "# Generating Instances\n",
    "\n",
    "In plain English, this code defines two functions that are used to generate instances for a list of data items. The first function, extract_json, is used to extract a JSON object from a response string. The second function, generate_instances, uses a language model to generate instances for each data item based on the instruction and the classification label. The function sends a prompt to the language model, extracts the instances from the response using the extract_json function, and adds the instances to the metadata of the item. Finally, the function saves the updated data to a new JSONL file.\n",
    "\n",
    "The extract_json function takes a response string and a prompt string as input, and attempts to extract a JSON object from the response string. It does this by finding the first occurrence of '{' and the last occurrence of '}' in the response string, and then attempting to parse the substring between those indices as a JSON object. If the parsing fails, the function retries up to a maximum number of times (specified by the max_retries parameter). If the function is unable to extract a valid JSON object after the maximum number of retries, it returns None.\n",
    "\n",
    "The generate_instances function takes a list of data items, an input-first template string, and an output-first template string as input. It iterates over each item in the data list, and for each item, it generates instances based on the instruction and the classification label. If the classification label is True, the function uses the output-first template to generate instances. If the classification label is False, the function uses the input-first template to generate instances. The function sends a prompt to the make_requests function, which makes a request to the Groq API and returns the response. The function then calls the extract_json function to extract the instances from the response, and adds the instances to the metadata of the item. Finally, the function saves the updated data to a new JSONL file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdafb599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response {\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"instruction\": \"Explain how the provided scenario might relate to your own personal experiences or observations.\",\n",
      "      \"input\": \"I am wondering how the concept of a remote work setup could possibly work for someone in a career that involves hands-on physical labor, like a mechanic.\",\n",
      "      \"output\": \"As someone who has worked from home during periods of high demand for my services, I can relate to the struggle to maintain focus and productivity without the traditional structure of an office environment. In my experience, setting a dedicated workspace and establishing a strict schedule has been crucial to avoiding distractions and meeting deadlines. I also understand the concerns about the potential for isolation and disconnection from colleagues and clients, which is why I prioritize regular video calls and online meetings to stay connected.\"\n",
      "    },\n",
      "    {\n",
      "      \"instruction\": \"Explain how the provided scenario might relate to your own personal experiences or observations.\",\n",
      "      \"input\": \"How does a service like 'rent-a-car' benefit the environment?\",\n",
      "      \"output\": \"As someone who has relied on public transportation for many years, I can appreciate the convenience of alternative transportation options like 'rent-a-car' services, especially for individuals without direct access to public transportation. In my experience, these services can also promote sustainable practices, such as carpooling and fuel-efficient vehicles, which can reduce carbon emissions. While it's true that these services may contribute to overall traffic congestion, I believe that responsible usage and innovative solutions can help mitigate these negative impacts.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response {\n",
      "  \"task\": \"Analyze and identify the underlying assumptions and biases in each of the given statements.\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Assumption: Experts' opinions are superior\",\n",
      "      \"input\": \"The most important indicator of a good investment is the recommendation of a financial expert.\",\n",
      "      \"output\": \"Assumption: Experts' opinions are superior\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Bias: Confirmation bias\",\n",
      "      \"input\": \"I only read news sources that confirm my political beliefs, and I never consider opposing views.\",\n",
      "      \"output\": \"Bias: Confirmation bias\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Assumption: Wealth is the ultimate measure of success\",\n",
      "      \"input\": \"The person with the biggest house and the most luxurious car is the most successful person in the world.\",\n",
      "      \"output\": \"Assumption: Wealth is the ultimate measure of success\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Bias: Gender stereotypes\",\n",
      "      \"input\": \"Women are naturally more nurturing and caring, while men are naturally more aggressive and competitive.\",\n",
      "      \"output\": \"Bias: Gender stereotypes\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Assumption: People are motivated by self-interest\",\n",
      "      \"input\": \"Everyone is only looking out for themselves and will do whatever it takes to get ahead.\",\n",
      "      \"output\": \"Assumption: People are motivated by self-interest\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Bias: Racial bias\",\n",
      "      \"input\": \"I don't want to hire an employee from a different race because they might not fit in with the team.\",\n",
      "      \"output\": \"Bias: Racial bias\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Assumption: Technology is the ultimate solution\",\n",
      "      \"input\": \"We can solve all of our environmental problems with a new app or a fancy new gadget.\",\n",
      "      \"output\": \"Assumption: Technology is the ultimate solution\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response {\n",
      "  \"task\": \"Develop a 2-paragraph summary that highlights the key points and main arguments of the provided text.\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Summary Provided\",\n",
      "      \"input\": \"The article discusses the impact of climate change on global food production. It argues that rising temperatures and changing precipitation patterns will lead to reduced crop yields and food security issues. The author suggests that implementing sustainable agricultural practices and reducing greenhouse gas emissions can help mitigate these effects.\",\n",
      "      \"output\": \"Summary Provided\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Summary Missing\",\n",
      "      \"input\": \"The article is about climate change, but it doesn't provide a clear summary of the key points. It jumps between different topics and doesn't have a clear structure.\",\n",
      "      \"output\": \"Summary Missing\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Summary Accuracy\",\n",
      "      \"input\": \"The summary accurately captures the main arguments of the article. It identifies the key points and provides a clear overview of the author's stance on climate change.\",\n",
      "      \"output\": \"Summary Accuracy\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response Here is the JSON output for the given task:\n",
      "\n",
      "{\n",
      "  \"task\": \"If the scenario describes an action, what is the recommended step to take in a similar situation?\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Call emergency services\",\n",
      "      \"input\": \"Someone is choking and struggling to breathe.\",\n",
      "      \"output\": \"Call emergency services\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Stay calm and observe\",\n",
      "      \"input\": \"You see a slight fire in a neighbor's kitchen, but it's not spreading.\",\n",
      "      \"output\": \"Stay calm and observe\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Activate your alarm system\",\n",
      "      \"input\": \"You've just left your house and notice the front door is slightly ajar.\",\n",
      "      \"output\": \"Activate your alarm system\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Seek medical attention\",\n",
      "      \"input\": \"You've just fallen and hit your head while walking down the stairs.\",\n",
      "      \"output\": \"Seek medical attention\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Call for backup\",\n",
      "      \"input\": \"You're being approached by a suspicious person while walking alone at night.\",\n",
      "      \"output\": \"Call for backup\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response {\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"instruction\": \"List three alternative solutions to the problem of reducing air pollution in cities, each with a brief explanation of its advantages and disadvantages.\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Solution 1: Implement Electric Vehicle Charging Infrastructure\n",
      "Advantages: Reduces tailpipe emissions, supports environmentally friendly transportation\n",
      "Disadvantages: High initial investment, potentially limited usage.\n",
      "\n",
      "Solution 2: Implement Advanced Waste Management Systems\n",
      "Advantages: Reduces waste sent to landfills, recycles materials for reuse\n",
      "Disadvantages: High upfront costs, requires significant changes to waste collection infrastructure.\n",
      "\n",
      "Solution 3: Promote Green-friendly Public Transportation Systems\n",
      "Advantages: Reduces traffic congestion, decreases air pollution from vehicles\n",
      "Disadvantages: Requires extensive changes to public transportation networks, may not be feasible in all areas.\"\n",
      "    },\n",
      "    {\n",
      "      \"instruction\": \"List three alternative solutions to the problem of improving data storage, each with a brief explanation of its advantages and disadvantages.\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Solution 1: Implement Cloud Storage Services\n",
      "Advantages: Scalable, accessible from anywhere, reduces storage costs\n",
      "Disadvantages: Data security concerns, reliance on internet connectivity\n",
      "\n",
      "Solution 2: Utilize Solid-state Drives for Data Storage\n",
      "Advantages: Faster data read-write speeds, secure data storage\n",
      "Disadvantages: Higher cost per GB, limited storage capacity\n",
      "\n",
      "Solution 3: Implement Distributed Hash Table Storage Systems\n",
      "Advantages: Highly scalable, reduplicated data for redundancy\n",
      "Disadvantages: Complex system architecture, potential security vulnerabilities\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Error: Invalid JSON. Retrying...\n",
      "Error: Invalid JSON. Retrying...\n",
      "Response {\n",
      "  \"task\": \"Identify the underlying assumption or biased perspective in each given statement and explain how it affects the conversation or decision-making process.\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Assumption of stereotyping\",\n",
      "      \"input\": \"Most black people are athletic and good at sports.\",\n",
      "      \"output\": \"The assumption of stereotyping affects the conversation by imposing a limited and inaccurate view of an entire racial group, potentially leading to exclusion and discrimination.\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Biased perspective on gender roles\",\n",
      "      \"input\": \"Women are naturally more nurturing and emotional than men.\",\n",
      "      \"output\": \"The biased perspective affects the decision-making process by influencing gender-based expectations and potentially limiting opportunities for individuals whose gender identity does not conform to societal norms.\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Confirmation bias\",\n",
      "      \"input\": \"All the studies I've seen on climate change support the idea that humans are responsible for global warming.\",\n",
      "      \"output\": \"The assumption of confirmation bias affects the conversation by selectively seeking information that supports a pre-existing opinion, leading to an incomplete understanding of the topic and potentially contributing to biases in decision-making.\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Assumption of cultural superiority\",\n",
      "      \"input\": \"Other cultures may be interesting to observe, but Western societies are inherently more superior in terms of values and principles.\",\n",
      "      \"output\": \"The assumption of cultural superiority affects the conversation by dismissing the validity of non-Western cultures and potentially leading to marginalization and cultural appropriation.\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Biased perspective on ability\",\n",
      "      \"input\": \"Someone with a disability cannot work in a fast-paced environment.\",\n",
      "      \"output\": \"The biased perspective affects the decision-making process by imposing arbitrary limitations on individuals based on their abilities, potentially excluding them from opportunities and limiting their potential.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response Here are the examples for the task:\n",
      "\n",
      "{\n",
      "  \"task\": \"Explain how the given situation illustrates or challenges the given stereotype.\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Illustrates\",\n",
      "      \"input\": \"A group of gamers are extremely social and communicative, contrary to the common stereotype that gamers are antisocial.\",\n",
      "      \"output\": \"Illustrates\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Challenges\",\n",
      "      \"input\": \"A famous actress is a natural beauty with no makeup, dispelling the stereotype that actresses all rely on surgery and makeup to look good.\",\n",
      "      \"output\": \"Challenges\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Illustrates\",\n",
      "      \"input\": \"The stereotype that Asian students are more studious is further solidified by the high academic achievement of most Asian students in a particular school.\",\n",
      "      \"output\": \"Illustrates\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Challenges\",\n",
      "      \"input\": \"A successful businesswoman who has a loving family and is not too busy for her child, contradicting the stereotype that high-powered career women are neglectful parents.\",\n",
      "      \"output\": \"Challenges\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response {\n",
      "  \"task\": \"Explain how the provided concept is used in a real-world scenario.\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Marketing\",\n",
      "      \"input\": \"Concept: Customer segments. Explain how this concept is used in real-world scenario.\",\n",
      "      \"output\": \"In real-world marketing scenario, customer segments are used to divide customers into distinct groups based on demographics, behavior, or preferences. For example, a company can segment its customers based on age, income, and education to create targeted marketing campaigns that resonate with each group.\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Healthcare\",\n",
      "      \"input\": \"Concept: Personalized medicine. Explain how this concept is used in real-world scenario.\",\n",
      "      \"output\": \"In real-world healthcare scenario, personalized medicine is used to tailor treatment plans to individual patients based on their unique genetic profiles and medical histories. For example, a doctor can use genetic testing to identify the most effective treatment for a patient's rare genetic disorder.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Response {\n",
      "  \"task\": \"Choose an appropriate title for an email based on the provided text, considering clarity and relevance.\",\n",
      "  \"examples\": [\n",
      "    {\n",
      "      \"class_label\": \"Confidentiality Alert\",\n",
      "      \"input\": \"Hi, this is confidential. Please do not share this information with anyone.\",\n",
      "      \"output\": \"Confidentiality Alert\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Invoice and Payment Details\",\n",
      "      \"input\": \"Your recent purchase details are below. Please find the payment instructions and related information.\",\n",
      "      \"output\": \"Invoice and Payment Details\"\n",
      "    },\n",
      "    {\n",
      "      \"class_label\": \"Meeting Invitation: Important Discussion\",\n",
      "      \"input\": \"You are cordially invited to a meeting to discuss the upcoming project milestones. Your attendance is required.\",\n",
      "      \"output\": \"Meeting Invitation: Important Discussion\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json(response, prompt, max_retries=3):\n",
    "    # Find the first \"{\" and the last \"}\"\n",
    "    start = response.find('{')\n",
    "    end = response.rfind('}')\n",
    "    if start != -1 and end != -1:\n",
    "        json_str = response[start:end+1]\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Error: Invalid JSON. Retrying...\")\n",
    "            if max_retries > 0:\n",
    "                # Make another call to make_requests\n",
    "                new_response = make_requests([prompt], stop_sequences=[])[0][\"response\"][\"choices\"][0][\"text\"]\n",
    "                return extract_json(new_response, prompt, max_retries - 1)\n",
    "            else:\n",
    "                print(\"Error: Max retries reached. Unable to get valid JSON.\")\n",
    "                return None\n",
    "    else:\n",
    "        print(\"Error: No JSON object found in the response. Retrying...\")\n",
    "        if max_retries > 0:\n",
    "            # Make another call to make_requests\n",
    "            new_response = make_requests([prompt], stop_sequences=[])[0][\"response\"][\"choices\"][0][\"text\"]\n",
    "            return extract_json(new_response, prompt, max_retries - 1)\n",
    "        else:\n",
    "            print(\"Error: Max retries reached. Unable to get valid JSON.\")\n",
    "            return None\n",
    "\n",
    "def generate_instances(data, input_first_template, output_first_template):\n",
    "    for item in data:\n",
    "        instruction = item[\"instruction\"]\n",
    "        is_classification = item[\"metadata\"][\"is_classification\"]\n",
    "        if is_classification:\n",
    "            # Use the output-first template for classification tasks\n",
    "            prompt = output_first_template_for_clf + \" \" + instruction + \"\\n\"\n",
    "            prompt += \"\\n\\nPlease return the output in JSON format with the keys 'task' and 'examples'.\"\n",
    "            response = make_requests([prompt], stop_sequences=[])[0][\"response\"][\"choices\"][0][\"text\"]\n",
    "            print(\"Response\", response)\n",
    "            instances = extract_json(response, prompt)\n",
    "            if instances:\n",
    "                item[\"metadata\"][\"instances\"] = instances\n",
    "        else:\n",
    "            # Use the input-first template for non-classification tasks\n",
    "            prompt = input_first_template + \" \" + instruction\n",
    "            prompt += \"\\n\\nPlease return the output in JSON format with the keys 'examples'.\"\n",
    "            response = make_requests([prompt], stop_sequences=[])[0][\"response\"][\"choices\"][0][\"text\"]\n",
    "            print(\"Response\", response)\n",
    "            instances = extract_json(response, prompt)\n",
    "            if instances:\n",
    "                item[\"metadata\"][\"instances\"] = instances\n",
    "\n",
    "# Open the classified instructions JSONL file\n",
    "with open(\"classified_instructions.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Generate instances for each instruction and add them to the metadata\n",
    "generate_instances(data, input_first_template_for_gen, output_first_template_for_clf)\n",
    "\n",
    "# Save the updated data to a new JSONL file\n",
    "with open(\"instructions_with_instances.jsonl\", \"w\") as f:\n",
    "    for item in data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd115a",
   "metadata": {},
   "source": [
    "# Preparing data for finetuning \n",
    "\n",
    "In plain English, this code prepares the data for fine-tuning a language model. It reads the data from a JSONL file, extracts the instruction, input, and output for each example, formats the prompt and completion strings, shuffles the instances, and writes the instances to a new JSONL file. The new file contains the data in the format required for fine-tuning the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8668809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def prepare_finetuning_data(input_file, output_file):\n",
    "    # Open the input file and load the data\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    # Initialize an empty list to store the instances\n",
    "    instances = []\n",
    "\n",
    "    # Iterate over each item in the data\n",
    "    for item in data:\n",
    "        # Extract the instruction and classification label from the item\n",
    "        instruction = item[\"instruction\"]\n",
    "        is_classification = item[\"metadata\"][\"is_classification\"]\n",
    "\n",
    "        # Iterate over each example in the item\n",
    "        for example in item[\"metadata\"][\"instances\"][\"examples\"]:\n",
    "            # If the task is a classification task, set the input and output accordingly\n",
    "            if is_classification:\n",
    "                input = example[\"input\"]\n",
    "                output = example[\"class_label\"]\n",
    "            # If the task is not a classification task, set the input and output accordingly\n",
    "            else:\n",
    "                input = example[\"input\"]\n",
    "                output = example[\"output\"]\n",
    "\n",
    "            # Format the prompt and completion strings based on the instruction and input\n",
    "            prompt = f\"{instruction}\\n\\nInput: {input}\\n\\nOutput:\"\n",
    "\n",
    "            # Append a dictionary containing the prompt and completion to the instances list\n",
    "            instances.append({\"prompt\": prompt, \"completion\": output})\n",
    "\n",
    "    # Shuffle the instances list to ensure that the data is well-mixed for training\n",
    "    random.shuffle(instances)\n",
    "\n",
    "    # Write the instances list to a JSONL file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for instance in instances:\n",
    "            f.write(json.dumps(instance) + \"\\n\")\n",
    "\n",
    "# Call the function with the input and output file paths\n",
    "input_file = \"instructions_with_instances.jsonl\"\n",
    "output_file = \"finetuning_data.jsonl\"\n",
    "prepare_finetuning_data(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4d6879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ff40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1b6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3bce18-ff85-41d5-be12-2cbc94a59208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1ea7e-e230-493a-a779-314bccd3c3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084997c-444f-46b0-8529-c5c522c52b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
